{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS__mzEiZ6Ew","executionInfo":{"status":"ok","timestamp":1712929292544,"user_tz":-480,"elapsed":3045,"user":{"displayName":"Archer914","userId":"03017676274708570535"}},"outputId":"944a10f5-b707-465b-f2b9-2382ac4b95c3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Xi9icUpOy4oG","executionInfo":{"status":"ok","timestamp":1712929302952,"user_tz":-480,"elapsed":10411,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"outputs":[],"source":["import torch\n","import cv2\n","import os\n","import numpy as np\n","import shutil\n","from google.colab.patches import cv2_imshow\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import math\n","from PIL import Image\n","import torch.nn as nn\n","import yaml\n","import random\n","from google.colab import files\n","import sys\n","import time\n","from torch.utils.data import random_split\n","import matplotlib.pyplot as plt\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 檢查是否有可用的 CUDA 設備（通常是顯卡，支援 GPU 運算），如果有，就將 device 變數設置為 \"cuda\"，否則設置為 \"cpu\"。\n","from __future__ import print_function\n","import zipfile\n","import os\n","import pdb\n","import torch\n","import h5py\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","from torchvision import datasets, transforms, utils\n","from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms, utils\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.axes_grid1 import ImageGrid\n","\n","from torch.autograd import Variable\n","# from logger import Logger\n","import pdb\n","import os\n","import re\n","import numpy as np\n","import time\n","\n","\n","import torch\n","import cv2\n","import os\n","# os.chdir('/content/drive/MyDrive/Colab Notebooks/Simple_DE') # this path is the path of the current .ipynb\n","import numpy as np\n","import shutil\n","from google.colab.patches import cv2_imshow\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","import math\n","from PIL import Image\n","import torch.nn as nn\n","import yaml\n","import random\n","from google.colab import files\n","import sys\n","import time\n","from torch.utils.data import random_split\n","import matplotlib.pyplot as plt\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # 檢查是否有可用的 CUDA 設備（通常是顯卡，支援 GPU 運算），如果有，就將 device 變數設置為 \"cuda\"，否則設置為 \"cpu\"。\n","from torch.optim.lr_scheduler import LambdaLR"]},{"cell_type":"code","source":["def load_config(file_path):\n","    with open(file_path, 'r') as file:\n","        config = yaml.safe_load(file)\n","    return config"],"metadata":{"id":"adC1eOcqZuaG","executionInfo":{"status":"ok","timestamp":1712929302953,"user_tz":-480,"elapsed":8,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/Model/config/config.yml' # main\n","# file_path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/Model/config/config.yml' # free\n","config = load_config(file_path)"],"metadata":{"id":"IdtTcF29ZvCW","executionInfo":{"status":"ok","timestamp":1712929302953,"user_tz":-480,"elapsed":7,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["output_height = 64\n","output_width = 64\n","batch_size = 32"],"metadata":{"id":"ZjgUAeX6wx0-","executionInfo":{"status":"ok","timestamp":1712929302953,"user_tz":-480,"elapsed":7,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class TransposeDepthInput(object):\n","    def __call__(self, depth):\n","        depth = depth.transpose((2, 0, 1))\n","        depth = torch.from_numpy(depth)\n","        depth = depth.view(1, depth.shape[0], depth.shape[1], depth.shape[2])\n","        depth = nn.functional.interpolate(depth, size=(output_height, output_width), mode='bilinear', align_corners=False)\n","        # depth = torch.log(depth)\n","        return depth[0]"],"metadata":{"id":"VId-4IUyzb-Q","executionInfo":{"status":"ok","timestamp":1712929302953,"user_tz":-480,"elapsed":6,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["rgb_data_transforms = transforms.Compose([\n","    transforms.Resize((output_height, output_width)),    # Different for Input Image & Depth Image\n","    transforms.ToTensor(),\n","    ])"],"metadata":{"id":"SaP1szmnzxHG","executionInfo":{"status":"ok","timestamp":1712929302954,"user_tz":-480,"elapsed":7,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["depth_data_transforms = transforms.Compose([\n","    TransposeDepthInput(),\n","])"],"metadata":{"id":"bL0NTcvpz1Jh","executionInfo":{"status":"ok","timestamp":1712929302954,"user_tz":-480,"elapsed":7,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["input_for_plot_transforms = transforms.Compose([\n","    transforms.Resize((output_height, output_width)),    # Different for Input Image & Depth Image\n","    transforms.ToTensor(),\n","])"],"metadata":{"id":"ozRr-fLGz3U0","executionInfo":{"status":"ok","timestamp":1712929302954,"user_tz":-480,"elapsed":7,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class NYUDataset(Dataset):\n","    def calculate_mean(self, images):\n","        mean_image = np.mean(images, axis=0)\n","        return mean_image\n","\n","    def __init__(self, filename, type, rgb_transform = None, depth_transform = None):\n","        f = h5py.File(filename, 'r')\n","        if type == \"training\":\n","            self.images = f['images'][0:1400]\n","            self.depths = f['depths'][0:1400]\n","        elif type == \"validation\":\n","            self.images = f['images'][1024:1248]\n","            self.depths = f['depths'][1024:1248]\n","        elif type == \"test\":\n","            self.images = f['images'][1400:]\n","            self.depths = f['depths'][1400:]\n","        self.rgb_transform = rgb_transform\n","        self.depth_transform = depth_transform\n","        self.mean_image = self.calculate_mean(f['images'][0:1449])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        image = self.images[idx]\n","        # image = (image - self.mean_image)/np.std(image)\n","        image = image.transpose((2, 1, 0))\n","        # image = (image - image.min())/(image.max() - image.min())\n","        # image = image * 255\n","        # image = image.astype('uint8')\n","        image = Image.fromarray(image)\n","        if self.rgb_transform:\n","            image = self.rgb_transform(image)\n","        depth = self.depths[idx]\n","        depth = np.reshape(depth, (1, depth.shape[0], depth.shape[1]))\n","        depth = depth.transpose((2, 1, 0))\n","        if self.depth_transform:\n","            depth = self.depth_transform(depth)\n","        sample = {'image': image, 'depth': depth}\n","        return sample"],"metadata":{"id":"n66TbtLz0Gak","executionInfo":{"status":"ok","timestamp":1712929302954,"user_tz":-480,"elapsed":6,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# path = '/content/drive/MyDrive/Colab Notebooks/共用區/Simple_DE/nyu_depth_v2_labeled.mat' # for free account\n","path = '/content/drive/MyDrive/Colab Notebooks/Simple_DE/nyu_depth_v2_labeled.mat' # for main account\n","train_loader = torch.utils.data.DataLoader(NYUDataset( path,\n","                                                       'training',\n","                                                        rgb_transform = rgb_data_transforms,\n","                                                        depth_transform = depth_data_transforms),\n","                                            batch_size = batch_size,\n","                                            shuffle = True, num_workers = 5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAQ6uF7F0uni","outputId":"a1abadd4-0147-45be-be99-d7e5cda51b5e","executionInfo":{"status":"ok","timestamp":1712929352724,"user_tz":-480,"elapsed":49776,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":["val_loader = torch.utils.data.DataLoader(NYUDataset( path,\n","                                                       'test',\n","                                                        rgb_transform = rgb_data_transforms,\n","                                                        depth_transform = depth_data_transforms),\n","                                            batch_size = batch_size,\n","                                            shuffle = False, num_workers = 5)\n","\n","\n","# train_loader = val_loader"],"metadata":{"id":"gWDCKlJLzRUY","executionInfo":{"status":"ok","timestamp":1712929367603,"user_tz":-480,"elapsed":14904,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["class Upsample(nn.Module): # this\n","    def __init__(self, in_channels, with_conv):\n","        super().__init__()\n","        self.with_conv = with_conv\n","        if self.with_conv:\n","            self.conv = torch.nn.Conv2d(in_channels,  # this conv let the size unchanged\n","                                        in_channels,\n","                                        kernel_size=3,\n","                                        stride=1,\n","                                        padding=1)\n","\n","    def forward(self, x):\n","        x = torch.nn.functional.interpolate(\n","            x, scale_factor=2.0, mode=\"nearest\") # double the size\n","        if self.with_conv:\n","            x = self.conv(x)\n","        return x"],"metadata":{"id":"JkWjVUn_WSXh","executionInfo":{"status":"ok","timestamp":1712929367603,"user_tz":-480,"elapsed":27,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["class Downsample(nn.Module):\n","    def __init__(self, in_channels, with_conv):\n","        super().__init__()\n","        self.with_conv = with_conv\n","        if self.with_conv:\n","            # no asymmetric padding in torch conv, must do it ourselves\n","            self.conv = torch.nn.Conv2d(in_channels,  # halves the size\n","                                        in_channels,\n","                                        kernel_size=3,\n","                                        stride=2,\n","                                        padding=0)\n","\n","    def forward(self, x):\n","        if self.with_conv:\n","            pad = (0, 1, 0, 1)\n","            x = torch.nn.functional.pad(x, pad, mode=\"constant\", value=0) # 此動作相當於在每個圖片的channel的右邊下面pad 0\n","            x = self.conv(x)\n","        else:\n","            x = torch.nn.functional.avg_pool2d(x, kernel_size=2, stride=2)\n","        return x"],"metadata":{"id":"nIng2nc5WXJv","executionInfo":{"status":"ok","timestamp":1712929367603,"user_tz":-480,"elapsed":26,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class ResnetBlock(nn.Module):\n","    def __init__(self, *, in_channels, out_channels=None, conv_shortcut=False,\n","                 dropout):\n","        super().__init__()\n","\n","        self.in_channels = in_channels\n","        self.Lrelu = nn.ELU()\n","        # self.Lrelu = nonlinearity\n","        out_channels = in_channels if out_channels is None else out_channels\n","        self.out_channels = out_channels\n","        self.use_conv_shortcut = conv_shortcut\n","\n","        self.norm1 =nn.BatchNorm2d(in_channels)     # 這裡上面define的Normalize有點像是class的感覺\n","        self.conv1 = torch.nn.Conv2d(in_channels, # size unchanged\n","                                     out_channels,\n","                                     kernel_size=3,\n","                                     stride=1,\n","                                     padding=1)\n","\n","        self.norm2 = nn.BatchNorm2d(out_channels)\n","        self.dropout = torch.nn.Dropout(dropout) # param為機率\n","        self.conv2 = torch.nn.Conv2d(out_channels, # size unchanged\n","                                     out_channels,\n","                                     kernel_size=3,\n","                                     stride=1,\n","                                     padding=1)\n","        if self.in_channels != self.out_channels:\n","            if self.use_conv_shortcut:\n","                self.conv_shortcut = torch.nn.Conv2d(in_channels,   # size unchanged\n","                                                     out_channels,\n","                                                     kernel_size=3,\n","                                                     stride=1,\n","                                                     padding=1)\n","            else:\n","                self.nin_shortcut = torch.nn.Conv2d(in_channels,    # size unchanged\n","                                                    out_channels,\n","                                                    kernel_size=1,\n","                                                    stride=1,\n","                                                    padding=0)\n","\n","\n","    def forward(self, x):\n","        h = x\n","        h = self.norm1(h)    # normalize\n","\n","        h = self.Lrelu(h)  # sigmoid\n","        h = self.conv1(h)    # channel become out_channel\n","\n","\n","        h = self.norm2(h)\n","        h = self.Lrelu(h)\n","        h = self.dropout(h)\n","        h = self.conv2(h)\n","\n","        if self.in_channels != self.out_channels:  # 如果inchannel和outchannel不同需要把輸入值channel也調整成一樣，用上conv2D，若inchannel和outchannel一樣就直接加\n","            if self.use_conv_shortcut:\n","                x = self.conv_shortcut(x)\n","            else:\n","                x = self.nin_shortcut(x)\n","\n","        return x+h"],"metadata":{"id":"PFPVGgP4Wa51","executionInfo":{"status":"ok","timestamp":1712929367603,"user_tz":-480,"elapsed":25,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# modified\n","class AttnBlock(nn.Module):\n","    def __init__(self, in_channels):\n","        super().__init__()\n","        self.in_channels = in_channels\n","\n","        self.norm = nn.BatchNorm2d(in_channels)\n","        self.q = torch.nn.Conv2d(in_channels, # in_cha == out_cha and the kernel size = 1, and size unchanged\n","                                 in_channels,\n","                                 kernel_size=1,\n","                                 stride=1,\n","                                 padding=0)\n","        self.k = torch.nn.Conv2d(in_channels,\n","                                 in_channels,\n","                                 kernel_size=1,\n","                                 stride=1,\n","                                 padding=0)\n","        self.v = torch.nn.Conv2d(in_channels,\n","                                 in_channels,\n","                                 kernel_size=1,\n","                                 stride=1,\n","                                 padding=0)\n","        self.proj_out = torch.nn.Conv2d(in_channels,\n","                                        in_channels,\n","                                        kernel_size=1,\n","                                        stride=1,\n","                                        padding=0)\n","        self.norm2 = nn.BatchNorm2d(in_channels)\n","\n","    def forward(self, x):\n","        h_ = x\n","        h_ = self.norm(h_)\n","        q = self.q(h_)\n","        k = self.k(h_)\n","        v = self.v(h_)\n","\n","        # compute attention\n","        b, c, h, w = q.shape # (batch, channel, height, width)\n","        q = q.reshape(b, c, h*w)\n","        q = q.permute(0, 2, 1)   # b,hw,c.  # 此兩變換(reshape + permute)詳細情形如下格，簡單來說最外圈還是每一個data(一張照片)，\n","                                # 往內一圈則是把該資料的所有channel(rgb)的同個位置放在一起\n","        k = k.reshape(b, c, h*w)  # b,c,hw # 單一此變換則是外圈是data，向內一圈則是該data一個channel內所有的值\n","        w_ = torch.bmm(q, k)     # b,hw,hw    w[b,i,j]=sum_c q[b,i,c]k[b,c,j]\n","        # 注意這邊是q * k，是把不同channels的同個位置變成vector然後內積，這樣跟cnn最大的差別是cnn只會在同一個區塊做相關性，attention卻在channels中的每個位置會相互做相關性\n","        w_ = w_ * (int(c)**(-0.5)) # 為何不是 * (int(h * w) ** (-0.5))?\n","        w_ = torch.nn.functional.softmax(w_, dim=2)\n","\n","        # attend to values\n","        v = v.reshape(b, c, h*w)\n","        w_ = w_.permute(0, 2, 1)   # b,hw,hw (first hw of k, second of q)\n","        # b, c,hw (hw of q) h_[b,c,j] = sum_i v[b,c,i] w_[b,i,j]\n","        h_ = torch.bmm(v, w_)\n","        h_ = h_.reshape(b, c, h, w)\n","\n","        h_ = self.norm2(self.proj_out(h_))\n","\n","\n","        return x+h_"],"metadata":{"id":"KJVHxiE5Wdrb","executionInfo":{"status":"ok","timestamp":1712929367603,"user_tz":-480,"elapsed":25,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["class ConvBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(ConvBlock, self).__init__()\n","        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n","        self.bn = nn.BatchNorm2d(out_channels)\n","        self.relu = nn.ELU()\n","        # self.Lrelu = nn.ELU()\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.bn(x)\n","        x = self.relu(x)\n","        return x"],"metadata":{"id":"nkMJSji_pPtc","executionInfo":{"status":"ok","timestamp":1712929367603,"user_tz":-480,"elapsed":25,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self, config, want_print):\n","        super().__init__()\n","        self.config = config\n","        self.print = want_print\n","        ch, out_ch, ch_mult = config['model']['ch'], config['model']['out_ch'], tuple(config['model']['ch_mult'])\n","        # ch = 128, out_ch = 3\n","        num_res_blocks = config['model']['num_res_blocks']\n","        # num_res_blocks = 2\n","        attn_resolutions = config['model']['attn_resolutions']\n","        attn_resolutions = [32, ]\n","        # attn_resolution = [16, ]\n","        dropout = config['model']['dropout']\n","        # dropout = 0.0\n","        in_channels = config['model']['in_channels']\n","        # in_channels = 3\n","        resolution = config['data']['image_size']\n","        resolution = 64\n","        # resolution = 256\n","        resamp_with_conv = config['model']['resamp_with_conv']\n","        # resamp_with_conv = True\n","\n","\n","\n","        if config['model']['type'] == 'bayesian':\n","            self.logvar = nn.Parameter(torch.zeros(num_timesteps))\n","\n","        self.ch = ch\n","        ch_mult = (1, 2, 2)\n","        # ch_mult = (1, 2)\n","\n","        self.num_resolutions = len(ch_mult)\n","        # num_resolutions = 4\n","        self.num_res_blocks = num_res_blocks\n","        self.resolution = resolution\n","        self.in_channels = in_channels\n","\n","\n","\n","\n","# nonlinear\n","\n","        curr_res = resolution\n","        in_ch_mult = (1,)+ch_mult\n","        # in_ch_mult = (1, 1, 1, 2, 2)\n","\n","        self.conv_down1 = ConvBlock(3, 16)\n","        self.conv_down2 = ConvBlock(16, 32)\n","        self.conv_down3 = ConvBlock(32, 64)\n","        self.conv_down4 = ConvBlock(64, 128)\n","\n","        self.down = nn.ModuleList()\n","        block_in = None\n","\n","\n","        # self.conv_in = torch.nn.Conv2d(3,\n","        #                                self.ch,\n","        #                                kernel_size=3,\n","        #                                stride=1,\n","        #                                padding=1)\n","        for i_level in range(self.num_resolutions):\n","            block = nn.ModuleList()\n","            attn = nn.ModuleList()\n","            block_in = ch*in_ch_mult[i_level]\n","            block_out = ch*ch_mult[i_level]\n","            for i_block in range(self.num_res_blocks):\n","\n","                block.append(ResnetBlock(in_channels=block_in,\n","                                         out_channels=block_out,\n","\n","                                         dropout=dropout))\n","                block_in = block_out\n","                if curr_res in attn_resolutions:\n","                    print(curr_res)\n","                    attn.append(AttnBlock(block_in))\n","            down = nn.Module()\n","            down.block = block\n","            down.attn = attn\n","            if i_level != self.num_resolutions-1:\n","                down.downsample = Downsample(block_in, resamp_with_conv)\n","                curr_res = curr_res // 2\n","            self.down.append(down)\n","\n","        # middle\n","        self.mid = nn.Module()\n","        self.mid.block_1 = ResnetBlock(in_channels=block_in,\n","                                       out_channels=block_in,\n","\n","                                       dropout=dropout)\n","        self.mid.attn_1 = AttnBlock(block_in)\n","        self.mid.block_2 = ResnetBlock(in_channels=block_in,\n","                                       out_channels=block_in,\n","\n","                                       dropout=dropout)\n","\n","        # upsampling\n","        self.up = nn.ModuleList()\n","        for i_level in reversed(range(self.num_resolutions)):\n","            block = nn.ModuleList()\n","            attn = nn.ModuleList()\n","            block_out = ch*ch_mult[i_level]\n","            skip_in = ch*ch_mult[i_level]\n","            for i_block in range(self.num_res_blocks+1):\n","                if i_block == self.num_res_blocks:\n","                    skip_in = ch*in_ch_mult[i_level] # 最後一個block時inchannel數可能變少\n","                block.append(ResnetBlock(in_channels=block_in+skip_in,\n","                                         out_channels=block_out,\n","\n","                                         dropout=dropout))\n","                block_in = block_out\n","                if curr_res in attn_resolutions:\n","                    attn.append(AttnBlock(block_in))\n","            up = nn.Module()\n","            up.block = block\n","            up.attn = attn\n","            if i_level != 0:\n","                up.upsample = Upsample(block_in, resamp_with_conv)\n","                curr_res = curr_res * 2\n","            self.up.insert(0, up)  # prepend to get consistent order, (0, up)代表在ModuleList()的0位置插入up這個Module\n","\n","        # end\n","        self.norm_out = nn.BatchNorm2d(block_in)\n","\n","        self.Lrelu = nn.ELU()\n","\n","        self.conv_up1 = ConvBlock(128, 64)\n","        self.conv_up2 = ConvBlock(64, 32)\n","        self.conv_up3 = ConvBlock(32, 16)\n","        self.conv_up4 = ConvBlock(16, 3)\n","        self.conv_up5 = ConvBlock(3, 1)\n","    def forward(self, image):\n","\n","\n","\n","        # downsampling down 裡面有好幾個元素，每個元素包含block(resblock), attn, downsample，其中attn只有幾個元素會有，downsample除了最後一個元素以外都有\n","        # 整個流程就是把x送進conv2D 然後送進down裡面經過resblock和部份attn downsample(conv2D)\n","        # hs = [self.conv_in(image)]\n","        h = image\n","        if self.print:\n","            print(\"original {}\".format(h.shape))\n","        h = self.conv_down1(h)\n","        if self.print:\n","            print(\"conv_down1 {}\".format(h.shape))\n","        h = self.conv_down2(h)\n","        if self.print:\n","            print(\"conv_down2 {}\".format(h.shape))\n","        h = self.conv_down3(h)\n","        if self.print:\n","            print(\"conv_down3 {}\".format(h.shape))\n","        h = self.conv_down4(h)\n","        if self.print:\n","            print(\"conv_down4 {}\".format(h.shape))\n","        hs = [h]\n","        if self.print:\n","            print(hs[-1].shape)\n","\n","\n","\n","        for i_level in range(self.num_resolutions):\n","            for i_block in range(self.num_res_blocks):\n","\n","                h = self.down[i_level].block[i_block](hs[-1]) # h 如果可以是attn就是attn 不然就是res, note that h是把值喂進去模塊後的值，要把hs的最後跟time embedded送進去\n","                if self.print:\n","                    print(\"res {}\".format(h.shape))\n","\n","\n","                if len(self.down[i_level].attn) > 0:\n","                    h = self.down[i_level].attn[i_block](h)\n","                    if self.print:\n","                        print(\"this is attn {}\".format(h.shape))\n","\n","                hs.append(h)\n","            if i_level != self.num_resolutions-1:\n","                h_temp = self.down[i_level].downsample(hs[-1])\n","                if self.print:\n","                    print(\"downsample {}\".format(h_temp.shape))\n","                hs.append(h_temp)\n","        # return hs\n","\n","        # middle\n","        h = hs[-1]\n","\n","        h = self.mid.block_1(h)\n","        if self.print:\n","            print(\"mid res {}\".format(h.shape))\n","        h = self.mid.attn_1(h)\n","        if self.print:\n","            print(\"mid attn {}\".format(h.shape))\n","        h = self.mid.block_2(h)\n","        if self.print:\n","            print(\"mid res {}\".format(h.shape))\n","\n","\n","        # upsampling\n","        for i_level in reversed(range(self.num_resolutions)):\n","            for i_block in range(self.num_res_blocks+1):\n","\n","                h_cat = torch.cat([h, hs.pop()], dim=1)\n","                if self.print:\n","                    print(\"this is cat {}\".format(h_cat.shape))\n","                h = self.up[i_level].block[i_block](h_cat) # u-net的cat down\n","                if self.print:\n","                    print(\"res {}\".format(h.shape))\n","                if len(self.up[i_level].attn) > 0:\n","                    h = self.up[i_level].attn[i_block](h)\n","                    if self.print:\n","                        print(\"this is attn {}\".format(h.shape))\n","\n","            if i_level != 0:\n","                h = self.up[i_level].upsample(h)\n","                if self.print:\n","                    print(\"this is upsample {}\".format(h.shape))\n","\n","\n","        # end\n","\n","\n","\n","        h = self.norm_out(h)\n","\n","\n","\n","        h = self.Lrelu(h)\n","\n","        h = self.conv_up1(h)\n","        if self.print:\n","            print(\"conv_up1 {}\".format(h.shape))\n","        h = self.conv_up2(h)\n","        if self.print:\n","            print(\"conv_up2 {}\".format(h.shape))\n","        h = self.conv_up3(h)\n","        if self.print:\n","            print(\"conv_up3 {}\".format(h.shape))\n","        h = self.conv_up4(h)\n","        if self.print:\n","            print(\"conv_up4 {}\".format(h.shape))\n","        h = self.conv_up5(h)\n","        if self.print:\n","            print(\"conv_up5 {}\".format(h.shape))\n","\n","        return h\n"],"metadata":{"id":"_6E0y2LCWlPe","executionInfo":{"status":"ok","timestamp":1712929367604,"user_tz":-480,"elapsed":25,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = Model(config, False)\n","model.to(device)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmpMuy39-szX","outputId":"8a338b7f-22b8-427b-e98a-e49c179df0b6","executionInfo":{"status":"ok","timestamp":1712929367604,"user_tz":-480,"elapsed":25,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["32\n","32\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (conv_down1): ConvBlock(\n","    (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_down2): ConvBlock(\n","    (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_down3): ConvBlock(\n","    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_down4): ConvBlock(\n","    (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (down): ModuleList(\n","    (0): Module(\n","      (block): ModuleList(\n","        (0-1): 2 x ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (attn): ModuleList()\n","      (downsample): Downsample(\n","        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2))\n","      )\n","    )\n","    (1): Module(\n","      (block): ModuleList(\n","        (0): ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (nin_shortcut): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1): ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (attn): ModuleList(\n","        (0-1): 2 x AttnBlock(\n","          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (downsample): Downsample(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))\n","      )\n","    )\n","    (2): Module(\n","      (block): ModuleList(\n","        (0-1): 2 x ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","        )\n","      )\n","      (attn): ModuleList()\n","    )\n","  )\n","  (mid): Module(\n","    (block_1): ResnetBlock(\n","      (Lrelu): ELU(alpha=1.0)\n","      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","    (attn_1): AttnBlock(\n","      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (block_2): ResnetBlock(\n","      (Lrelu): ELU(alpha=1.0)\n","      (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (up): ModuleList(\n","    (0): Module(\n","      (block): ModuleList(\n","        (0): ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (nin_shortcut): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (1-2): 2 x ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (nin_shortcut): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (attn): ModuleList()\n","    )\n","    (1): Module(\n","      (block): ModuleList(\n","        (0-1): 2 x ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","        (2): ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (nin_shortcut): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (attn): ModuleList(\n","        (0-2): 3 x AttnBlock(\n","          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (q): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (k): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (v): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (proj_out): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (upsample): Upsample(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","    (2): Module(\n","      (block): ModuleList(\n","        (0-2): 3 x ResnetBlock(\n","          (Lrelu): ELU(alpha=1.0)\n","          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (dropout): Dropout(p=0.0, inplace=False)\n","          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","          (nin_shortcut): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        )\n","      )\n","      (attn): ModuleList()\n","      (upsample): Upsample(\n","        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      )\n","    )\n","  )\n","  (norm_out): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (Lrelu): ELU(alpha=1.0)\n","  (conv_up1): ConvBlock(\n","    (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_up2): ConvBlock(\n","    (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_up3): ConvBlock(\n","    (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_up4): ConvBlock(\n","    (conv): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n","  (conv_up5): ConvBlock(\n","    (conv): Conv2d(3, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ELU(alpha=1.0)\n","  )\n",")"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["NO_epochs = 700\n","save_frequency = 5\n","LR = 0.001\n","\n","clip_value = 1e-2\n","batch_size = 32\n","optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n","first_epoch = 0\n","start = 460\n","warm_up_period = 20"],"metadata":{"id":"7ycY1hoAtoHJ","executionInfo":{"status":"ok","timestamp":1712929368338,"user_tz":-480,"elapsed":4,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def warmup_scheduler(epoch):\n","    if epoch < warm_up_period:\n","        return (epoch / warm_up_period)\n","    else:\n","        return 1 / 100\n"],"metadata":{"id":"O18G683utowe","executionInfo":{"status":"ok","timestamp":1712929368338,"user_tz":-480,"elapsed":3,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["scheduler = LambdaLR(optimizer, lr_lambda = warmup_scheduler)"],"metadata":{"id":"NI7n6SAitqTB","executionInfo":{"status":"ok","timestamp":1712929368338,"user_tz":-480,"elapsed":3,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["if first_epoch:\n","    for epoch in range(1, NO_epochs + 1):\n","        current_lr = optimizer.param_groups[0]['lr']\n","        print('lr in the last epoch: {}'.format(current_lr))\n","        start_time = time.time()\n","        mean_epoch_loss = []\n","        mean_epoch_loss_val = []\n","        epoch_gradient = {}\n","        for image in train_loader:\n","            scheduler.step(epoch)\n","            input_img = image['image'].to(torch.float32).to(device)\n","            target_depth = image['depth'].to(torch.float32).to(device)\n","\n","            pred_depth = model(input_img)\n","            # --------------------exit--------\n","            # sys.exit()\n","            # --------------------exit--------\n","\n","            optimizer.zero_grad()\n","            loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","            # params = list(model.parameters())\n","            # weight_tensor = params[490]\n","            # chains = torch.autograd.grad(loss, weight_tensor, retain_graph=True)\n","            # for chain in chains:\n","            #     print(chain)\n","            mean_epoch_loss.append(loss.item())\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","            # for param in model.parameters():\n","            #     if param.grad is not None:\n","            #         param.grad.data.clamp_(-clip_value, clip_value)\n","            optimizer.step()\n","            #---gradient---vvv\n","            for name, param in model.named_parameters():\n","                if param.grad == None:\n","                    epoch_gradient[name + 'zero'] = 1\n","                elif name not in epoch_gradient:\n","                    epoch_gradient[name] = param.grad.clone()\n","                else:\n","                    epoch_gradient[name] += param.grad\n","            #---gradient---^^^\n","        with torch.inference_mode():\n","            for  image in val_loader:\n","\n","                input_img = image['image'].to(torch.float32).to(device)\n","                target_depth = image['depth'].to(torch.float32).to(device)\n","                pred_depth = model(input_img)\n","\n","                val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","                mean_epoch_loss_val.append(val_loss.item())\n","\n","        if epoch % save_frequency == 0 or epoch == NO_epochs:\n","            checkpoint = {\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","                'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","                'valid_loss' : np.mean(mean_epoch_loss_val),\n","                'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","                'gradients' : epoch_gradient\n","            }\n","\n","            torch.save(checkpoint, 'weight{}.pth'.format(epoch))\n","            source_path = 'weight{}.pth'.format(epoch)\n","            destination_path = '/content/drive/MyDrive/Colab Notebooks/Unet_Depth_Estimation/Checkpoint2/weight' # main account\n","            # destination_path = '/content/drive/MyDrive/Colab Notebooks/共用區/NYU_Diffusion_Depth_Estimation/Checkpoint' # free account\n","\n","            shutil.copy(source_path, destination_path)\n","\n","        #---計算時間---vvv\n","        end_time = time.time()\n","        exe_time = end_time - start_time\n","        hours, remainder = divmod(exe_time, 3600)\n","        minutes, seconds = divmod(remainder, 60)\n","        #---計算時間---^^^\n","\n","        #-----以下是存loss的---vvv\n","        checkpoint = {\n","        'epoch': epoch,\n","        'valid_loss' : np.mean(mean_epoch_loss_val),\n","        'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","        'time' : exe_time\n","        }\n","\n","        torch.save(checkpoint, 'loss{}.pth'.format(epoch))\n","        source_path = 'loss{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Unet_Depth_Estimation/Checkpoint2/loss' # main\n","        # destination_path = '/content/drive/MyDrive/Colab Notebooks/共用區/NYU_Diffusion_Depth_Estimation/Checkpoint' # free\n","        shutil.copy(source_path, destination_path)\n","        #-----以下是存loss的---^^^\n","\n","        print('---')\n","        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","        print(\"time = {}:{}:{}\".format(int(hours), int(minutes), int(seconds)))\n","\n"],"metadata":{"id":"yhvXAjHftr0A","executionInfo":{"status":"ok","timestamp":1712929368338,"user_tz":-480,"elapsed":3,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["if not first_epoch:\n","\n","\n","    load_path = '/content/drive/MyDrive/Colab Notebooks/Unet_Depth_Estimation/Checkpoint2/weight/weight{}.pth'.format(start)\n","    checkpoint = torch.load(load_path, map_location = torch.device(device))\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","    for epoch in range(start + 1, NO_epochs + 1):\n","        current_lr = optimizer.param_groups[0]['lr']\n","        print('lr in the last epoch: {}'.format(current_lr))\n","        start_time = time.time()\n","        mean_epoch_loss = []\n","        mean_epoch_loss_val = []\n","        epoch_gradient = {}\n","        for image in train_loader:\n","            scheduler.step(epoch)\n","            input_img = image['image'].to(torch.float32).to(device)\n","            target_depth = image['depth'].to(torch.float32).to(device)\n","            pred_depth = model(input_img)\n","            # --------------------exit--------\n","            # sys.exit()\n","            # --------------------exit--------\n","\n","            optimizer.zero_grad()\n","            loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","            # params = list(model.parameters())\n","            # weight_tensor = params[490]\n","            # chains = torch.autograd.grad(loss, weight_tensor, retain_graph=True)\n","            # for chain in chains:\n","            #     print(chain)\n","            mean_epoch_loss.append(loss.item())\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","            # for param in model.parameters():\n","            #     if param.grad is not None:\n","            #         param.grad.data.clamp_(-clip_value, clip_value)\n","            optimizer.step()\n","            #---gradient---vvv\n","            for name, param in model.named_parameters():\n","                if param.grad == None:\n","                    epoch_gradient[name + 'zero'] = 1\n","                elif name not in epoch_gradient:\n","                    epoch_gradient[name] = param.grad.clone()\n","                else:\n","                    epoch_gradient[name] += param.grad\n","            #---gradient---^^^\n","        with torch.inference_mode():\n","            for  image in val_loader:\n","                input_img = image['image'].to(torch.float32).to(device)\n","                target_depth = image['depth'].to(torch.float32).to(device)\n","                pred_depth = model(input_img)\n","\n","                val_loss = torch.nn.functional.mse_loss(target_depth, pred_depth)\n","                mean_epoch_loss_val.append(val_loss.item())\n","\n","        if epoch % save_frequency == 0 or epoch == NO_epochs:\n","            checkpoint = {\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(), # model.state_dict()是存下param的的值和形狀\n","                'optimizer_state_dict': optimizer.state_dict(), # optimizer.state_dict()則是存下優化器的param如momentum等等 不包含當下梯度\n","                'valid_loss' : np.mean(mean_epoch_loss_val),\n","                'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","                'gradients' : epoch_gradient\n","            }\n","\n","            torch.save(checkpoint, 'weight{}.pth'.format(epoch))\n","            source_path = 'weight{}.pth'.format(epoch)\n","            destination_path = '/content/drive/MyDrive/Colab Notebooks/Unet_Depth_Estimation/Checkpoint2/weight' # main account\n","            # destination_path = '/content/drive/MyDrive/Colab Notebooks/共用區/NYU_Diffusion_Depth_Estimation/Checkpoint' # free account\n","\n","            shutil.copy(source_path, destination_path)\n","\n","        #---計算時間---vvv\n","        end_time = time.time()\n","        exe_time = end_time - start_time\n","        hours, remainder = divmod(exe_time, 3600)\n","        minutes, seconds = divmod(remainder, 60)\n","        #---計算時間---^^^\n","\n","        #-----以下是存loss的---vvv\n","        checkpoint = {\n","        'epoch': epoch,\n","        'valid_loss' : np.mean(mean_epoch_loss_val),\n","        'loss' : np.mean(mean_epoch_loss), # 記得不能存tensor\n","        'time' : exe_time\n","        }\n","\n","        torch.save(checkpoint, 'loss{}.pth'.format(epoch))\n","        source_path = 'loss{}.pth'.format(epoch)\n","        destination_path = '/content/drive/MyDrive/Colab Notebooks/Unet_Depth_Estimation/Checkpoint2/loss' # main\n","        # destination_path = '/content/drive/MyDrive/Colab Notebooks/共用區/NYU_Diffusion_Depth_Estimation/Checkpoint' # free\n","        shutil.copy(source_path, destination_path)\n","        #-----以下是存loss的---^^^\n","\n","        print('---')\n","        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Val Loss {np.mean(mean_epoch_loss_val)}\")\n","        print(\"time = {}:{}:{}\".format(int(hours), int(minutes), int(seconds)))"],"metadata":{"id":"ylCIp4Q-tu2q","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1712932205702,"user_tz":-480,"elapsed":2837367,"user":{"displayName":"Archer914","userId":"03017676274708570535"}},"outputId":"a810992f-da73-4530-eedf-c30797588755"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["lr in the last epoch: 0.001\n"]},{"output_type":"stream","name":"stderr","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n","  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"output_type":"stream","name":"stdout","text":["---\n","Epoch: 346 | Train Loss 0.06087676113979383 | Val Loss 1.0799731314182281\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 347 | Train Loss 0.06030852762474255 | Val Loss 1.0894380807876587\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 348 | Train Loss 0.05875497751615264 | Val Loss 1.1033524870872498\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 349 | Train Loss 0.06452299624850805 | Val Loss 1.0995701849460602\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 350 | Train Loss 0.046605243855579334 | Val Loss 1.1029427647590637\n","time = 0:0:26\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 351 | Train Loss 0.05906771009110592 | Val Loss 1.0914305448532104\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 352 | Train Loss 0.05261093416166576 | Val Loss 1.0900542736053467\n","time = 0:0:20\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 353 | Train Loss 0.05190366172147068 | Val Loss 1.098490059375763\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 354 | Train Loss 0.050927472597157415 | Val Loss 1.0926260352134705\n","time = 0:0:20\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 355 | Train Loss 0.05063409883190285 | Val Loss 1.0968064367771149\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 356 | Train Loss 0.0539219069971957 | Val Loss 1.090798795223236\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 357 | Train Loss 0.04199199801818891 | Val Loss 1.0860590934753418\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 358 | Train Loss 0.059927860063246706 | Val Loss 1.1054211854934692\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 359 | Train Loss 0.05451693982732567 | Val Loss 1.0788225531578064\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 360 | Train Loss 0.055876830000091686 | Val Loss 1.0879656076431274\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 361 | Train Loss 0.04838888143951243 | Val Loss 1.080883413553238\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 362 | Train Loss 0.04342414142394608 | Val Loss 1.0729142427444458\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 363 | Train Loss 0.048669185997410255 | Val Loss 1.0765936374664307\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 364 | Train Loss 0.046076050409200514 | Val Loss 1.0778715014457703\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 365 | Train Loss 0.048699357716197315 | Val Loss 1.0991962254047394\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 366 | Train Loss 0.044838677033443346 | Val Loss 1.0783043205738068\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 367 | Train Loss 0.042315800039267 | Val Loss 1.0872436165809631\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 368 | Train Loss 0.051349244588478046 | Val Loss 1.066575974225998\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 369 | Train Loss 0.04310980240221728 | Val Loss 1.078090637922287\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 370 | Train Loss 0.05708580108528787 | Val Loss 1.0993491113185883\n","time = 0:0:26\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 371 | Train Loss 0.04431563628498803 | Val Loss 1.076896756887436\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 372 | Train Loss 0.04948990749703212 | Val Loss 1.0751818716526031\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 373 | Train Loss 0.046698614870282734 | Val Loss 1.0659078657627106\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 374 | Train Loss 0.04774439428001642 | Val Loss 1.0681606531143188\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 375 | Train Loss 0.04211193378168074 | Val Loss 1.0568054020404816\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 376 | Train Loss 0.05022234084423293 | Val Loss 1.0683828592300415\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 377 | Train Loss 0.04377844565632669 | Val Loss 1.0657075941562653\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 378 | Train Loss 0.0503209456378086 | Val Loss 1.0628002882003784\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 379 | Train Loss 0.039401299828155475 | Val Loss 1.0611129105091095\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 380 | Train Loss 0.0561690093441443 | Val Loss 1.0690967738628387\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 381 | Train Loss 0.042661687951873646 | Val Loss 1.0833986103534698\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 382 | Train Loss 0.04568202327936888 | Val Loss 1.0699952840805054\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 383 | Train Loss 0.05091431787745519 | Val Loss 1.0641164183616638\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 384 | Train Loss 0.04093120492656122 | Val Loss 1.073063224554062\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 385 | Train Loss 0.04016742757944898 | Val Loss 1.089314341545105\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 386 | Train Loss 0.04127296631817113 | Val Loss 1.0827051997184753\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 387 | Train Loss 0.045563656286421145 | Val Loss 1.0764023065567017\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 388 | Train Loss 0.05803405061702837 | Val Loss 1.0773645639419556\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 389 | Train Loss 0.04466257405213334 | Val Loss 1.0868209898471832\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 390 | Train Loss 0.04861200660128485 | Val Loss 1.075696736574173\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 391 | Train Loss 0.040611095684157175 | Val Loss 1.0756314992904663\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 392 | Train Loss 0.0478766054677015 | Val Loss 1.0557783246040344\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 393 | Train Loss 0.050364983903074804 | Val Loss 1.0843051373958588\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 394 | Train Loss 0.051081880927085876 | Val Loss 1.0617803633213043\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 395 | Train Loss 0.0424176494336941 | Val Loss 1.07548788189888\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 396 | Train Loss 0.04815898458896713 | Val Loss 1.08486670255661\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 397 | Train Loss 0.039790547283535656 | Val Loss 1.0726734101772308\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 398 | Train Loss 0.05633855208923871 | Val Loss 1.0826351940631866\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 399 | Train Loss 0.04739579266275872 | Val Loss 1.0915996730327606\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 400 | Train Loss 0.0401955477216027 | Val Loss 1.0710575580596924\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 401 | Train Loss 0.042619154661555185 | Val Loss 1.063469111919403\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 402 | Train Loss 0.04354757515036247 | Val Loss 1.0652732849121094\n","time = 0:0:20\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 403 | Train Loss 0.043729238508438524 | Val Loss 1.078360676765442\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 404 | Train Loss 0.04769306185401299 | Val Loss 1.0683356821537018\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 405 | Train Loss 0.0424924500879239 | Val Loss 1.0877178609371185\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 406 | Train Loss 0.04385584076358513 | Val Loss 1.068840503692627\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 408 | Train Loss 0.03978882027281956 | Val Loss 1.094205915927887\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 409 | Train Loss 0.054210927252742375 | Val Loss 1.0624107420444489\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 410 | Train Loss 0.0528541876595806 | Val Loss 1.060719758272171\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 411 | Train Loss 0.055402242578566074 | Val Loss 1.0605146288871765\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 412 | Train Loss 0.0483283259567212 | Val Loss 1.0648792684078217\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 413 | Train Loss 0.04078003586354581 | Val Loss 1.0622290074825287\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 414 | Train Loss 0.05039464673874053 | Val Loss 1.0904864966869354\n","time = 0:0:20\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 415 | Train Loss 0.05776097003201192 | Val Loss 1.0759930610656738\n","time = 0:0:30\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 416 | Train Loss 0.04930912665176121 | Val Loss 1.0730557441711426\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 417 | Train Loss 0.041989201891490004 | Val Loss 1.0707094371318817\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 418 | Train Loss 0.051548323297703806 | Val Loss 1.0690308809280396\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 419 | Train Loss 0.04218304364688017 | Val Loss 1.0683792233467102\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 420 | Train Loss 0.04548371909186244 | Val Loss 1.0809100568294525\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 421 | Train Loss 0.04414967155422677 | Val Loss 1.0715555250644684\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 422 | Train Loss 0.04554687004367059 | Val Loss 1.0718079507350922\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 423 | Train Loss 0.04511464213613759 | Val Loss 1.0743525326251984\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 424 | Train Loss 0.04541930065236308 | Val Loss 1.0636214315891266\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 425 | Train Loss 0.041230350605804815 | Val Loss 1.0706002116203308\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 426 | Train Loss 0.04181137346577915 | Val Loss 1.0600618422031403\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 427 | Train Loss 0.04746707380664619 | Val Loss 1.058784306049347\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 428 | Train Loss 0.04860829578881914 | Val Loss 1.0556801557540894\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 429 | Train Loss 0.04803376594050364 | Val Loss 1.0576003193855286\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 430 | Train Loss 0.04822155926376581 | Val Loss 1.056991845369339\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 431 | Train Loss 0.043812266466292465 | Val Loss 1.0716014206409454\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 432 | Train Loss 0.042513408698141575 | Val Loss 1.057892084121704\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 433 | Train Loss 0.04332324456084858 | Val Loss 1.0601984560489655\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 434 | Train Loss 0.047566271937367594 | Val Loss 1.063486635684967\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 435 | Train Loss 0.05728145455941558 | Val Loss 1.0647428631782532\n","time = 0:0:28\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 436 | Train Loss 0.04809659969230944 | Val Loss 1.058972716331482\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 437 | Train Loss 0.046335803852839905 | Val Loss 1.0612524151802063\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 438 | Train Loss 0.0488559745082801 | Val Loss 1.0518109202384949\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 439 | Train Loss 0.036768518134274265 | Val Loss 1.0495482087135315\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 440 | Train Loss 0.045311170503158464 | Val Loss 1.0630459487438202\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 441 | Train Loss 0.047488613265820524 | Val Loss 1.0493548810482025\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 442 | Train Loss 0.0379562489265068 | Val Loss 1.0418592393398285\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 443 | Train Loss 0.03902515349909663 | Val Loss 1.060287207365036\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 444 | Train Loss 0.03459487719969316 | Val Loss 1.0531474351882935\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 445 | Train Loss 0.043854378925805744 | Val Loss 1.053550511598587\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 446 | Train Loss 0.0431703702038662 | Val Loss 1.0542531311511993\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 447 | Train Loss 0.04647996344349601 | Val Loss 1.0540271997451782\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 448 | Train Loss 0.0505499010482295 | Val Loss 1.0510699152946472\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 449 | Train Loss 0.047249209389767864 | Val Loss 1.054194062948227\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 450 | Train Loss 0.040006614586507734 | Val Loss 1.0431618988513947\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 451 | Train Loss 0.04421979358250445 | Val Loss 1.0394745171070099\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 452 | Train Loss 0.04838360774076798 | Val Loss 1.0771809816360474\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 453 | Train Loss 0.04255757603625005 | Val Loss 1.0622432827949524\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 454 | Train Loss 0.0434417516331781 | Val Loss 1.0484860837459564\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 455 | Train Loss 0.047383361580696975 | Val Loss 1.0530835092067719\n","time = 0:0:24\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 456 | Train Loss 0.038037622601471165 | Val Loss 1.058843195438385\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 457 | Train Loss 0.054022345607253636 | Val Loss 1.0684244632720947\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 458 | Train Loss 0.04706061428243464 | Val Loss 1.0474686324596405\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 459 | Train Loss 0.042400488164275885 | Val Loss 1.0447306036949158\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 460 | Train Loss 0.039645245764404535 | Val Loss 1.0426764786243439\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 461 | Train Loss 0.04562537909739397 | Val Loss 1.043355017900467\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 462 | Train Loss 0.035578849598426714 | Val Loss 1.049801528453827\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 463 | Train Loss 0.04134557125243274 | Val Loss 1.0455240607261658\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 464 | Train Loss 0.04764312763952396 | Val Loss 1.0458861887454987\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 465 | Train Loss 0.04189506808126515 | Val Loss 1.0397833585739136\n","time = 0:0:25\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 466 | Train Loss 0.039073505100201474 | Val Loss 1.05185928940773\n","time = 0:0:23\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 467 | Train Loss 0.03938122343441302 | Val Loss 1.0532537698745728\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 468 | Train Loss 0.04247932567853819 | Val Loss 1.0541152954101562\n","time = 0:0:22\n","lr in the last epoch: 0.0001\n","---\n","Epoch: 469 | Train Loss 0.04023763749071143 | Val Loss 1.0529672801494598\n","time = 0:0:21\n","lr in the last epoch: 0.0001\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-de820db897ce>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# for chain in chains:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#     print(chain)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mmean_epoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"T7huwuE-zr_N","executionInfo":{"status":"aborted","timestamp":1712932205703,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for batch in train_loader:\n","    image = batch['image'].to(device)\n","    depth = batch['depth'].to(device)\n","    break\n","print(depth.shape)"],"metadata":{"id":"KwZ9M-BOaXiv","executionInfo":{"status":"aborted","timestamp":1712932205703,"user_tz":-480,"elapsed":8,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# ans = model(image)"],"metadata":{"id":"i2kDVNL-azYF","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print(ans.shape)"],"metadata":{"id":"-fa4DvQDnZE9","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# for idx in range(len(ans)):\n","#     print(ans[idx].shape)\n"],"metadata":{"id":"D1LnkNqTdVCv","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def custom_loss_function(output, target):\n","    di = target - output\n","    n = (output_height * output_width)\n","    di2 = torch.pow(di, 2)\n","    fisrt_term = torch.sum(di2,(1,2,3))/n\n","    second_term = 0.5*torch.pow(torch.sum(di,(1,2,3)), 2)/ (n**2)\n","    # loss = fisrt_term - second_term\n","    loss = fisrt_term\n","    return loss.mean()"],"metadata":{"id":"QhDpMDYo-1gW","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# optimizer = optim.SGD(model.parameters(), lr = 0.1, momentum=0.9)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","save_frequency = 5\n"],"metadata":{"id":"UdSEcwP8E1ug","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def warmup_scheduler(epoch):\n","    if epoch < 10:\n","        return (epoch / 10)\n","    else:\n","        return 1"],"metadata":{"id":"fRC8xgH8Mk9b","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scheduler = LambdaLR(optimizer, lr_lambda = warmup_scheduler)"],"metadata":{"id":"33NmNXLmMm3j","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 200\n","for epoch in range(1, epochs + 1):\n","    training_loss = train_Unet(epoch)\n","    print(\"epoch : {} | training loss : {}\".format(epoch, training_loss))\n","\n","    # if epoch % 1 == 0:\n","    #     validate_Unet(epoch, training_loss)\n","    # if epoch % 1 == 0:\n","    #     model_file = folder_name + \"/model_\" + str(epoch) + \".pth\"\n","    #     torch.save(model.state_dict(), model_file)"],"metadata":{"id":"jCL5wU9RSApi","executionInfo":{"status":"aborted","timestamp":1712932205704,"user_tz":-480,"elapsed":8,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["epochs = 600\n","start = 485\n","weight_path = '/content/drive/MyDrive/Colab Notebooks/Unet_Depth_Estimation/Checkpoint/weight{}.pth'.format(start)\n","checkpoint = torch.load(weight_path, map_location = torch.device(device))\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","for epoch in range(start + 1, epochs + 1):\n","    training_loss = train_Unet_cont(epoch)\n","    print(\"epoch : {} | training loss : {}\".format(epoch, training_loss))"],"metadata":{"id":"uiQMbmDG3EKI","executionInfo":{"status":"aborted","timestamp":1712932205705,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"Yvm3hdsDXo-f","executionInfo":{"status":"aborted","timestamp":1712932205705,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ir__aJEQTxb2","executionInfo":{"status":"aborted","timestamp":1712932205705,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"u9RIvDTohK1e","executionInfo":{"status":"aborted","timestamp":1712932205705,"user_tz":-480,"elapsed":9,"user":{"displayName":"Archer914","userId":"03017676274708570535"}}},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}